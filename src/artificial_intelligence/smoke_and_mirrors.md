WnZ39p0Dgydaz1 6 hours ago [-]

As someone who has worked as a researcher in one of the big AI research labs, I completely agree with this post. There has been true progress in a few ML subfields over the past few years, most noticeably representation learning for image recognition and text/ translation, but 99% of what you read in both scientific papers (which are more PR than ever) and the general media is nothing but hype. Especially over the last 2-3 years or so I haven't seen anything novel. IMO that's mostly a result of the confluence of perverse incentives at various levels:

- Academics need to create PR and hype to increase their chances for grants

- PhD students need to publish papers, and thus convince reviewers, with unnecessarily complex and hype-filled language, that their papers are good. They are also more incentivized than ever to create their own personal brand (via hype-filled blog post or videos) to increase future employment opportunities. More PR also means more citations, which is metric academics are often evaluated on. After all, if you work on something related, you're pretty much obligated to cite research that everyone has heard about, right?

- Startups, as it has always been, jump on the latest trend to increase their chance of raising money from investors. They slap AI/ML onto their pitch decks to differentiate themselves from others, or to become eligible for AI-focused funds. In reality, none of them will ever use any of the new ML techniques because they are too brittle to work in real-world products or require many orders of magnitude more data then the startup will ever have.

- Big companies want to brand themselves as "thought-leaders" in AI to drive up their share prices, hire better talent, improve their public image, convince investors, etc.

- The general media has no idea what they are talking about and wants to generate clicks. Same as always.

Put all this together and you get the current AI hype cycle. We've seen this happen with lots of other technologies in the past, what's kind of new this time is the entrance of academia into the cycle. When I first started in (ML) academia I was under the naive impression that I would be doing hard and cold science - I was so wrong. Everyone is optimizing for their own objective (grants, salary, publications, etc, see above), which makes most of the published research completely useless or simply wrong. One of the, sometimes unspoken, criteria of choosing ML projects in many of these labs is "how much PR will this create". This useless "research" is then treated as if it was a proven method and picked up by startups to convince clueless investors or customers with "look at this latest paper, it's amazing, we will monetize this, we're at the forefront of AI!", or by the general media to create more hype and drive clicks.

One important point that the blog post makes that is always overlooked is this:

> Now what this diagram does not show, is the amount of money which went into AI in corresponding time periods.

With all the hype over the last few years, just think about how many billions of dollars and tens of thousands of some of the smartest people on this planet got into the field, often to make a quick buck. With this many resources invested, would you expect there to be no progress? Obviously there will be, but most of it is smoke and mirrors. People think that the progress comes due to new AI techniques (Neural Nets), but in reality, if you were to take the same people and money and forced them to make progress on the same problems using some other technique, let's say probabilistic models or even rule-based or symbolic systems, they would've done just as well, if not better.

https://news.ycombinator.com/item?id=21569645
